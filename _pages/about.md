---
layout: about
title: about
permalink: /
subtitle:
profile:
  align: left
  image: me.png
  image_circular: false # crops the image to make it circular
  address: <p align="left"><font size="2">Cambridge, MA, USA 02138<br>Graduate School of Arts and Sciences, Harvard University</font></p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
--- 
I recently obtained my Master's degree from [Harvard University](https://www.harvard.edu/) <img src="assets/img/h.png" alt="h" height="20px">.

**Currently**{: style="color: #990000; opacity: 0.80;" }, I am a member of the 
	AI4LIFE Group at 
	Harvard SEAS, working with Prof. 
	[Hima Lakkaraju](https://himalakkaraju.github.io/).
Also, I have been visiting the 
	[Stanford NLP Group](https://nlp.stanford.edu/) <img src="assets/img/Stanford.png" alt="s" height="19px"> , collaborating with Prof.
	[Diyi Yang](https://cs.stanford.edu/~diyiy/index.html) for one year.

Previously, I obtained my Bachelor's degree in Computer Science from 
	[TUM](https://www.tum.de/en/) <img src="assets/img/TUM.png" alt="tum" height="13px"> , with a minor in Computational Linguistics at 
	[LMU](https://www.lmu.de/en/) <img src="assets/img/LMU.jpeg" alt="lmu" height="18px"> . During my undergraduate studies, I was fortunate to be supervised by Prof. 
	[Hinrich Sch√ºtze](https://scholar.google.com/citations?user=qIL9dWUAAAAJ&hl=en) and [Timo Schick](https://scholar.google.de/citations?user=k8CKy5UAAAAJ&hl=en)
	at the [CIS](https://www.cis.uni-muenchen.de/), LMU.

My research interests lie in `LLM safety`, including alignment, robustness <a href="https://arxiv.org/abs/2305.13406">[1]</a><a href="https://arxiv.org/abs/2311.00915">[2]</a>, fairness <a href="https://arxiv.org/abs/2310.14607">[3]</a>, privacy <a href="https://arxiv.org/abs/2409.00138">[4]</a>, misinformation <a href="https://arxiv.org/abs/2311.09630">[5]</a>, jailbreaking, etc. Technically, I have also worked on `parameter-efficient adaptation & composition`<a href="https://arxiv.org/abs/2305.13406">[1]</a><a href="https://arxiv.org/abs/2311.00915">[2]</a><a href="https://arxiv.org/abs/2302.14413">[6]</a>  and `in-context learning`<a href="https://arxiv.org/abs/2310.14607">[3]</a><a href="https://arxiv.org/abs/2202.06133">[7]</a>.
